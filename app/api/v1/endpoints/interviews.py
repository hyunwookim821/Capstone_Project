from fastapi import APIRouter, HTTPException, WebSocket, WebSocketDisconnect, Depends, UploadFile, File
from typing import List, Any, Dict
import os
import base64
import uuid
import re
import google.generativeai as genai
import google.cloud.texttospeech as tts
import whisper
import anthropic
import httpx
from pydub import AudioSegment
from dotenv import load_dotenv
from sqlalchemy.orm import Session

from app.db.session import SessionLocal
from app import crud, models
from app.api import deps
from app.schemas.interview import InterviewCreate, QuestionCreate, AnswerCreate, InterviewSession, VideoAnalysisRequest
from app.schemas.analysis import Analysis, AnalysisCreate
from app.schemas.video_analysis import VideoAnalysisCreate
from app.utils.audio_analysis import analyze_speech_audio
from app.utils.video_analysis import analyze_video_landmarks

load_dotenv()

if os.path.exists("ffmpeg.exe"):
    AudioSegment.converter = os.path.abspath("ffmpeg.exe")

router = APIRouter()

@router.post("/", response_model=InterviewSession)
def create_interview_session(
    *,
    db: Session = Depends(deps.get_db),
    resume_id: int,
    current_user: models.User = Depends(deps.get_current_user)
):
    """
    Create a new interview session.
    """
    resume = crud.resume.get(db, resume_id=resume_id)
    if not resume or resume.user_id != current_user.user_id:
        raise HTTPException(status_code=404, detail="Resume not found or access denied")

    existing_questions = crud.interview.get_latest_questions_by_resume(db, resume_id=resume_id)
    
    if existing_questions:
        questions_text = [q.question_text for q in existing_questions]
    else:
        content = resume.content or ""
        if not content:
            raise HTTPException(status_code=400, detail="Resume content is empty")

        try:
            google_api_key = os.getenv("GOOGLE_API_KEY")
            gemini_model_name = os.getenv("GEMINI_MODEL")
            if not google_api_key or not gemini_model_name:
                raise HTTPException(status_code=500, detail="AI model configuration missing")

            genai.configure(api_key=google_api_key)
            model = genai.GenerativeModel(gemini_model_name)
            prompt = f"""ÎãπÏã†ÏùÄ ÏßÄÏõêÏûêÏùò Ïó≠ÎüâÏùÑ ÍπäÏù¥ ÏûàÍ≤å ÌååÏïÖÌïòÎ†§Îäî ÎÇ†Ïπ¥Î°úÏö¥ Î©¥Ï†ëÍ¥ÄÏûÖÎãàÎã§. ÎãπÏã†Ïùò ÏûÑÎ¨¥Îäî ÏßÄÏõêÏûêÏùò ÏûêÍ∏∞ÏÜåÍ∞úÏÑúÏôÄ ÏùºÎ∞òÏ†ÅÏù∏ Î©¥Ï†ë ÏßàÎ¨∏ÏùÑ Ï°∞Ìï©ÌïòÏó¨, ÌïµÏã¨ Ïó≠ÎüâÍ≥º Í≤ΩÌóòÏùò ÏßÑÏúÑ, Í∑∏Î¶¨Í≥† Î¨∏Ï†ú Ìï¥Í≤∞ Îä•Î†•ÏùÑ Ï¢ÖÌï©Ï†ÅÏúºÎ°ú Í≤ÄÏ¶ùÌï† Ïàò ÏûàÎäî Î©¥Ï†ë ÏßàÎ¨∏ Î™©Î°ùÏùÑ ÏÉùÏÑ±ÌïòÎäî Í≤ÉÏûÖÎãàÎã§. Î∞òÎìúÏãú ÏïÑÎûò Í∑úÏπôÍ≥º Ï∂úÎ†• ÌòïÏãùÏùÑ ÏóÑÍ≤©ÌïòÍ≤å Ï§ÄÏàòÌïòÏó¨ ÎãµÎ≥ÄÌï¥Ïïº Ìï©ÎãàÎã§.\n\n$$Í∑úÏπô$$\n\nÏßàÎ¨∏ Ïú†Ìòï Ï°∞Ìï©: ÏßàÎ¨∏ Î™©Î°ùÏùÄ ÏïÑÎûò Îëê Í∞ÄÏßÄ Ïú†ÌòïÏùÑ Î∞òÎìúÏãú Ï°∞Ìï©ÌïòÏó¨ ÏÉùÏÑ±Ìï¥Ïïº Ìï©ÎãàÎã§.\n\nÏûêÍ∏∞ÏÜåÍ∞úÏÑú Í∏∞Î∞ò ÏßàÎ¨∏: ÏßÄÏõêÏûêÏùò ÏûêÍ∏∞ÏÜåÍ∞úÏÑúÏóê Î™ÖÏãúÎêú Í≤ΩÌóò, Ïó≠Îüâ, ÏÑ±Í≥º, Ïû•Îã®Ï†ê Îì±ÏùÑ ÍπäÏù¥ ÏûàÍ≤å ÌååÍ≥†ÎìúÎäî ÏßàÎ¨∏ÏûÖÎãàÎã§.\n\nÍ≥µÌÜµ ÏßàÎ¨∏: Î™®Îì† ÏßÄÏõêÏûêÏóêÍ≤å Î¨ºÏñ¥Î≥º Ïàò ÏûàÎäî ÏßÅÎ¨¥/ÌöåÏÇ¨ Í¥ÄÎ†® ÏßàÎ¨∏Ïù¥ÎÇò Ïù∏ÏÑ±/Í∞ÄÏπòÍ¥Ä ÏßàÎ¨∏ÏûÖÎãàÎã§. (Ïòà: ÏûÖÏÇ¨ ÌõÑ Ìè¨Î∂Ä, ÏßÄÏõê ÎèôÍ∏∞, ÎßàÏßÄÎßâÏúºÎ°ú ÌïòÍ≥† Ïã∂ÏùÄ Îßê Îì±)\n\nÏßàÎ¨∏ Í∞úÏàò: ÏûêÍ∏∞ÏÜåÍ∞úÏÑú ÎÇ¥Ïö©Ïùò Î∂ÑÎüâÍ≥º ÍπäÏù¥Î•º Í≥†Î†§ÌïòÏó¨, Îëê Ïú†ÌòïÏùÑ Ìï©Ï≥ê ÏµúÏÜå 5Í∞úÏóêÏÑú ÏµúÎåÄ 15Í∞úÏùò ÏßàÎ¨∏ÏùÑ Ïú†ÎèôÏ†ÅÏúºÎ°ú ÏÉùÏÑ±Ìï©ÎãàÎã§.\n\nÏïïÎ∞ï ÏßàÎ¨∏ Ìè¨Ìï®: Ï†ÑÏ≤¥ ÏßàÎ¨∏ Ï§ë 1~2Í∞úÎäî ÏßÄÏõêÏûêÏùò ÎÖºÎ¶¨Î†•, ÏúÑÍ∏∞ ÎåÄÏ≤ò Îä•Î†• Îì±ÏùÑ ÌôïÏù∏ÌïòÍ∏∞ ÏúÑÌïú ÏïïÎ∞ï ÏßàÎ¨∏(Íº¨Î¶¨ ÏßàÎ¨∏, Î∞òÎåÄ ÏÉÅÌô© Í∞ÄÏ†ï Îì±)ÏùÑ Ìè¨Ìï®Ìï¥Ïïº Ìï©ÎãàÎã§. ÏïïÎ∞ï ÏßàÎ¨∏ÏùÄ üå∂Ô∏è ÏïÑÏù¥ÏΩòÏúºÎ°ú Î™ÖÌôïÌûà ÌëúÏãúÌïòÏÑ∏Ïöî.\n\nÌòïÏãù Ï§ÄÏàò: ÏïÑÎûòÏóê Ï†úÏãúÎêú **$$Ï∂úÎ†• ÌòïÏãù$$**Ïùò Íµ¨Ï°∞ÏôÄ ÏàúÏÑúÎ•º Î∞òÎìúÏãú ÏßÄÏºúÏïº Ìï©ÎãàÎã§. Í≥µÌÜµ ÏßàÎ¨∏ ÏïûÏóêÎäî [Í≥µÌÜµ] ÎßêÎ®∏Î¶¨Î•º Î∂ôÏó¨Ï£ºÏÑ∏Ïöî.\n\n$$Ï∂úÎ†• ÌòïÏãù$$\n\nÏòàÏÉÅ Î©¥Ï†ë ÏßàÎ¨∏ Î¶¨Ïä§Ìä∏\n\n(ÏûêÍ∏∞ÏÜåÍ∞úÏÑú ÎÇ¥Ïö©Ïóê Í∏∞Î∞òÌïú ÏùºÎ∞ò ÏßàÎ¨∏ 1)\n\n$$Í≥µÌÜµ$$\n\n (Î™®Îì† ÏßÄÏõêÏûêÏóêÍ≤å Ìï† Ïàò ÏûàÎäî ÏßÅÎ¨¥/ÌöåÏÇ¨ Í¥ÄÎ†® Í≥µÌÜµ ÏßàÎ¨∏)\n\nüå∂Ô∏è (ÏûêÍ∏∞ÏÜåÍ∞úÏÑú ÎÇ¥Ïö©Ïóê Í∏∞Î∞òÌïú ÏïïÎ∞ï ÏßàÎ¨∏)\n\n(Ïù¥Ìïò ÏßàÎ¨∏Îì§ÏùÑ Í∑úÏπôÏóê ÎßûÍ≤å ÏÉùÏÑ±...)\n\n$$Í≥µÌÜµ$$\n\n (Î™®Îì† ÏßÄÏõêÏûêÏóêÍ≤å Ìï† Ïàò ÏûàÎäî Ïù∏ÏÑ±/Í∞ÄÏπòÍ¥Ä Í¥ÄÎ†® Í≥µÌÜµ ÏßàÎ¨∏)\n\nÏù¥Ï†ú Ïù¥ ÏßÄÏπ®Ïóê Îî∞Îùº ÏïÑÎûò ÏûêÍ∏∞ÏÜåÍ∞úÏÑúÎ•º Î∂ÑÏÑùÌïòÍ≥† ÏòàÏÉÅ Î©¥Ï†ë ÏßàÎ¨∏ÏùÑ ÏÉùÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.\n\n$$ÏßÄÏõêÏûê ÏûêÍ∏∞ÏÜåÍ∞úÏÑú$$\n\n\n{content}\n"""
            response = model.generate_content(prompt)
            
            raw_questions = response.text.split('\n')
            questions_text = []
            for q in raw_questions:
                q = q.strip()
                if not q or "ÏòàÏÉÅ Î©¥Ï†ë ÏßàÎ¨∏ Î¶¨Ïä§Ìä∏" in q or q == "$$Í≥µÌÜµ$$":
                    continue
                q = re.sub(r'^\d+\.\s*', '', q)
                q = q.replace('üå∂Ô∏è', '').strip()
                if q:
                    questions_text.append(q)

            if not questions_text:
                raise HTTPException(status_code=500, detail="Failed to generate questions.")

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"AI question generation failed: {str(e)}")

    cleaned_questions_text = []
    for q in questions_text:
        q = q.strip()
        if not q or "ÏòàÏÉÅ Î©¥Ï†ë ÏßàÎ¨∏ Î¶¨Ïä§Ìä∏" in q or q == "$$Í≥µÌÜµ$$":
            continue
        q = re.sub(r'^\d+\.\s*', '', q)
        q = q.replace('üå∂Ô∏è', '').strip()
        if q:
            cleaned_questions_text.append(q)
    questions_text = cleaned_questions_text

    interview_create = InterviewCreate(user_id=current_user.user_id, resume_id=resume_id)
    interview = crud.interview.create_interview(db=db, obj_in=interview_create)

    for q_text in questions_text:
        question_create = QuestionCreate(interview_id=interview.interview_id, question_text=q_text)
        crud.interview.create_question(db=db, obj_in=question_create)

    return InterviewSession(interview_id=interview.interview_id, questions=questions_text)


@router.get("/{interview_id}/results", response_model=Analysis)
async def get_interview_results(
    interview_id: int,
    db: Session = Depends(deps.get_db),
    current_user: models.User = Depends(deps.get_current_user),
):
    """
    Get the comprehensive analysis results for a finished interview.
    This is the single trigger for generating the final report.
    """
    interview = crud.interview.get_interview(db, interview_id=interview_id)
    if not interview or interview.user_id != current_user.user_id:
        raise HTTPException(status_code=404, detail="Interview not found or access denied")

    # If a full analysis already exists, return it to prevent re-generation.
    analysis = crud.analysis.get_analysis_by_interview(db, interview_id=interview_id)
    if analysis:
        return analysis

    # --- Gather All Data ---
    resume = crud.resume.get(db, resume_id=interview.resume_id)
    resume_content = resume.content if resume else ""

    questions = crud.interview.get_questions_by_interview(db, interview_id=interview_id)
    conversation_history = ""
    for q in questions:
        conversation_history += f"Q: {q.question_text}\n"
        if q.answers:
            conversation_history += f"A: {q.answers[0].answer_text}\n\n"

    if not conversation_history:
        raise HTTPException(status_code=400, detail="No questions or answers found for this interview.")

    # --- Audio Analysis ---
    audio_analysis_summary = ""
    total_speech_rate = 0
    total_silence_ratio = 0
    num_answers_with_audio = 0
    avg_speech_rate = None
    avg_silence_ratio = None

    for q in questions:
        if q.answers and q.answers[0].audio_path and os.path.exists(q.answers[0].audio_path):
            answer = q.answers[0]
            speech_rate, silence_ratio = analyze_speech_audio(answer.audio_path, answer.answer_text)
            total_speech_rate += speech_rate
            total_silence_ratio += silence_ratio
            num_answers_with_audio += 1
    
    if num_answers_with_audio > 0:
        avg_speech_rate = total_speech_rate / num_answers_with_audio
        avg_silence_ratio = total_silence_ratio / num_answers_with_audio
        audio_analysis_summary = f"""
---
### **ÏùåÏÑ± Î∂ÑÏÑù (ÎßêÌïòÍ∏∞ ÏäµÍ¥Ä)**
*   **ÌèâÍ∑† ÎßêÌïòÍ∏∞ ÏÜçÎèÑ:** {avg_speech_rate:.2f} WPM (Words Per Minute)
*   **Î®∏Î≠áÍ±∞Î¶º (Ïπ®Î¨µ) ÎπÑÏú®:** {avg_silence_ratio:.2f}%

(Ï∞∏Í≥†: Ïù¥ÏÉÅÏ†ÅÏù∏ ÎßêÌïòÍ∏∞ ÏÜçÎèÑÎäî Î∂ÑÎãπ 130-160 Îã®Ïñ¥(WPM)Ïù¥Î©∞, Ïπ®Î¨µ ÎπÑÏú®Ïù¥ ÎÜíÏùÑÏàòÎ°ù ÏÉùÍ∞ÅÏù¥ Í∏∏Ïñ¥ÏßÄÍ±∞ÎÇò ÏûêÏã†Í∞êÏù¥ Î∂ÄÏ°±Ìï¥ Î≥¥Ïùº Ïàò ÏûàÏäµÎãàÎã§.)
"""

    # --- Video Analysis ---
    video_analysis_summary = ""
    video_analysis_data = crud.video_analysis.get_by_interview_id(db, interview_id=interview_id)
    gaze_stability = None
    expression_stability = None
    posture_stability = None

    if video_analysis_data:
        gaze_stability = video_analysis_data.gaze_stability
        expression_stability = video_analysis_data.expression_stability
        posture_stability = video_analysis_data.posture_stability
        video_analysis_summary = f"""
---
### **ÏòÅÏÉÅ Î∂ÑÏÑù (ÏãúÍ∞ÅÏ†Å ÌÉúÎèÑ)**
*   **ÏãúÏÑ† ÏïàÏ†ïÏÑ±:** {gaze_stability:.4f} (ÎÇÆÏùÑÏàòÎ°ù ÏïàÏ†ïÏ†Å)
*   **ÌëúÏ†ï ÏïàÏ†ïÏÑ±:** {expression_stability:.4f} (ÎÇÆÏùÑÏàòÎ°ù ÏïàÏ†ïÏ†Å)
*   **ÏûêÏÑ∏ ÏïàÏ†ïÏÑ±:** {posture_stability:.4f} (ÎÇÆÏùÑÏàòÎ°ù ÏïàÏ†ïÏ†Å)

(Ï∞∏Í≥†: Ïù¥ ÏßÄÌëúÎì§ÏùÄ Ïã†Ï≤¥Ïùò ÎØ∏ÏÑ∏Ìïú ÏõÄÏßÅÏûÑÏùò ÌëúÏ§ÄÌé∏Ï∞®Î•º ÎÇòÌÉÄÎÇ¥Î©∞, ÏàòÏπòÍ∞Ä ÎÇÆÏùÑÏàòÎ°ù ÏãúÏÑ†, ÌëúÏ†ï, ÏûêÏÑ∏Í∞Ä ÏïàÏ†ïÏ†ÅÏù¥Í≥† ÏûêÏã†Í∞ê ÏûàÏñ¥ Î≥¥ÏûÑÏùÑ ÏùòÎØ∏Ìï©ÎãàÎã§.)
"""

    # --- AI Feedback Generation ---
    api_key = os.getenv("CLAUDE_API_KEY")
    claude_model = os.getenv("CLAUDE_MODEL")
    if not api_key or not claude_model:
        raise HTTPException(status_code=500, detail="Claude API configuration missing.")
    api_key = api_key.strip().strip('"').strip("'")

    prompt = f"""ÎãπÏã†ÏùÄ ÏàòÎßéÏùÄ Î©¥Ï†ë Í≤ΩÌóòÏùÑ Í∞ÄÏßÑ Ï†ÑÎ¨∏ Ï±ÑÏö© Ïª®ÏÑ§ÌÑ¥Ìä∏ÏûÖÎãàÎã§. ÎãπÏã†Ïùò ÏûÑÎ¨¥Îäî ÏïÑÎûò Ï†úÍ≥µÎêòÎäî ÏßÄÏõêÏûêÏùò "ÏûêÍ∏∞ÏÜåÍ∞úÏÑú", "Î©¥Ï†ë ÎåÄÌôîÎ°ù", "ÏùåÏÑ± Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞", "ÏòÅÏÉÅ Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞"Î•º Ï¢ÖÌï©Ï†ÅÏúºÎ°ú Î∂ÑÏÑùÌïòÏó¨, ÏßÄÏõêÏûêÏùò Ïó≠ÎüâÍ≥º Í∞úÏÑ†Ï†êÏóê ÎåÄÌïú Ïã¨Ï∏µÏ†ÅÏù∏ ÌîºÎìúÎ∞± Î¶¨Ìè¨Ìä∏Î•º ÏûëÏÑ±ÌïòÎäî Í≤ÉÏûÖÎãàÎã§.

Î∞òÎìúÏãú ÏïÑÎûòÏùò "Î∂ÑÏÑù Í∏∞Ï§Ä"Í≥º "Ï∂úÎ†• ÌòïÏãù"ÏùÑ ÏóÑÍ≤©ÌïòÍ≤å Ï§ÄÏàòÌïòÏó¨ Î¶¨Ìè¨Ìä∏Î•º ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî. (ÏòÅÏÉÅ Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÎã§Î©¥ Ìï¥Îãπ Î∂ÄÎ∂ÑÏùÄ ÏÉùÎûµÌïòÍ≥† Î¶¨Ìè¨Ìä∏Î•º ÏûëÏÑ±ÌïòÏÑ∏Ïöî.)

---
### **ÏûêÍ∏∞ÏÜåÍ∞úÏÑú**
```
{resume_content}
```
---
### **Î©¥Ï†ë ÎåÄÌôîÎ°ù**
```
{conversation_history}
```
{audio_analysis_summary}
{video_analysis_summary}
---
### **Î∂ÑÏÑù Í∏∞Ï§Ä**

1.  **ÎãµÎ≥ÄÏùò Î™ÖÌôïÏÑ± Î∞è ÎÖºÎ¶¨ÏÑ± (Clarity & Logic):**
    *   ÏßàÎ¨∏Ïùò ÏùòÎèÑÎ•º Ï†ïÌôïÌûà ÌååÏïÖÌïòÍ≥† ÏûàÎäîÍ∞Ä?
    *   ÎãµÎ≥ÄÏù¥ Ï≤¥Í≥ÑÏ†ÅÏù¥Í≥† Ïù¥Ìï¥ÌïòÍ∏∞ Ïâ¨Ïö¥Í∞Ä? (Ïòà: STAR Í∏∞Î≤ï ÌôúÏö©)
    *   Ï£ºÏû•Ïóê ÎåÄÌïú Í∑ºÍ±∞Í∞Ä Î™ÖÌôïÌïòÍ≥† ÌÉÄÎãπÌïúÍ∞Ä?

2.  **ÌïµÏã¨ Ïó≠Îüâ Î∞è Í≤ΩÌóò Ïñ¥ÌïÑ (Keyword & Experience):**
    *   ÏûêÍ∏∞ÏÜåÍ∞úÏÑúÏóê Ïñ∏Í∏âÎêú ÏûêÏã†Ïùò Í≤ΩÌóòÍ≥º Í∞ïÏ†êÏùÑ ÎãµÎ≥ÄÏóê Ïûò ÎÖπÏó¨ÎÇ¥Í≥† ÏûàÎäîÍ∞Ä?
    *   ÏßàÎ¨∏Í≥º Í¥ÄÎ†®Îêú ÏûêÏã†Ïùò ÌïµÏã¨ Ïó≠Îüâ ÌÇ§ÏõåÎìúÎ•º Ï†ÅÏ†àÌûà ÏÇ¨Ïö©ÌïòÍ≥† ÏûàÎäîÍ∞Ä?

3.  **Ïª§ÎÆ§ÎãàÏºÄÏù¥ÏÖò Ïä§ÌÇ¨ (ÏùåÏÑ± Î∞è ÏòÅÏÉÅ Ìè¨Ìï®):**
    *   ÏûêÏã†Í∞ê ÏûàÎäî Ïñ¥Ï°∞ÏôÄ Í∏çÏ†ïÏ†ÅÏù∏ ÌÉúÎèÑÎ•º Î≥¥Ïù¥ÎäîÍ∞Ä? (ÎåÄÌôî ÎÇ¥Ïö©, ÏùåÏÑ±, ÏòÅÏÉÅ Îç∞Ïù¥ÌÑ∞Î•º Ï¢ÖÌï©ÌïòÏó¨ Ï∂îÎ°†)
    *   Î∂àÌïÑÏöîÌïú Îã®Ïñ¥ÎÇò Î∞òÎ≥µÏ†ÅÏù∏ ÌëúÌòÑÏùÑ ÏµúÏÜåÌôîÌïòÍ≥† ÏûàÎäîÍ∞Ä?
    *   ÎßêÌïòÍ∏∞ ÏÜçÎèÑ, Î®∏Î≠áÍ±∞Î¶º, ÏãúÏÑ† Ï≤òÎ¶¨, ÌëúÏ†ï, ÏûêÏÑ∏ Îì±ÏùÄ Ï†ÅÏ†àÌïúÍ∞Ä? (ÏùåÏÑ± Î∞è ÏòÅÏÉÅ Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞ Ï∞∏Í≥†)

---
### **Ï∂úÎ†• ÌòïÏãù (Markdown)**

ÏïÑÎûò ÌòïÏãùÏùÑ Î∞òÎìúÏãú Ï§ÄÏàòÌïòÏó¨, Í∞Å Ìï≠Î™©Ïóê ÎåÄÌï¥ 1-5Ï†ê Ï≤ôÎèÑÎ°ú Ï†êÏàòÎ•º Îß§Í∏∞Í≥† Íµ¨Ï≤¥Ï†ÅÏù∏ ÌîºÎìúÎ∞±ÏùÑ ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.

# **AI Î©¥Ï†ë Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏**

## **Ï¢ÖÌï© ÌèâÍ∞Ä**
> Ï¥ùÌèâÏùÑ 2-3Î¨∏Ïû•ÏúºÎ°ú ÏöîÏïΩÌïòÏó¨ Ï†úÍ≥µÌï©ÎãàÎã§. ÏßÄÏõêÏûêÏùò Í∞ÄÏû• ÌÅ∞ Í∞ïÏ†êÍ≥º Í∞ÄÏû• ÏãúÍ∏âÌïú Í∞úÏÑ†Ï†êÏùÑ Ïñ∏Í∏âÌï¥ Ï£ºÏÑ∏Ïöî.

---

## **ÏÑ∏Î∂Ä Î∂ÑÏÑù**

### **1. ÎãµÎ≥ÄÏùò Î™ÖÌôïÏÑ± Î∞è ÎÖºÎ¶¨ÏÑ±**
*   **Ï†êÏàò:** [1-5Ï†ê]
*   **üëç ÏûòÌïú Ï†ê:**
    *   (Íµ¨Ï≤¥Ï†ÅÏù∏ ÎãµÎ≥Ä ÎÇ¥Ïö©ÏùÑ Ïù∏Ïö©ÌïòÎ©∞ Ïπ≠Ï∞¨)
*   **üëé Í∞úÏÑ†Ìï† Ï†ê:**
    *   (Íµ¨Ï≤¥Ï†ÅÏù∏ ÎãµÎ≥Ä ÎÇ¥Ïö©ÏùÑ Ïù∏Ïö©ÌïòÎ©∞ Í∞úÏÑ† Î∞©Ìñ• Ï†úÏãú)

### **2. ÌïµÏã¨ Ïó≠Îüâ Î∞è Í≤ΩÌóò Ïñ¥ÌïÑ**
*   **Ï†êÏàò:** [1-5Ï†ê]
*   **üëç ÏûòÌïú Ï†ê:**
    *   (ÏûêÍ∏∞ÏÜåÍ∞úÏÑú ÎÇ¥Ïö©Í≥º ÎãµÎ≥ÄÏùÑ ÎπÑÍµêÌïòÎ©∞ Ïπ≠Ï∞¨)
*   **üëé Í∞úÏÑ†Ìï† Ï†ê:**
    *   (ÎãµÎ≥ÄÏóêÏÑú ÏïÑÏâ¨Ïõ†Îçò Î∂ÄÎ∂ÑÍ≥º ÏûêÍ∏∞ÏÜåÍ∞úÏÑúÏùò Ïñ¥Îñ§ Í≤ΩÌóòÏùÑ Îçî Ïñ¥ÌïÑÌï† Ïàò ÏûàÏóàÎäîÏßÄ Ï†úÏïà)

### **3. Ïª§ÎÆ§ÎãàÏºÄÏù¥ÏÖò Ïä§ÌÇ¨ (ÏùåÏÑ± Î∞è ÏòÅÏÉÅ Ìè¨Ìï®)**
*   **Ï†êÏàò:** [1-5Ï†ê]
*   **üëç ÏûòÌïú Ï†ê:**
    *   (ÏûêÏã†Í∞ê ÏûàÎäî ÌëúÌòÑ, ÏïàÏ†ïÏ†ÅÏù∏ ÏãúÏÑ† Ï≤òÎ¶¨, Í∏çÏ†ïÏ†ÅÏù∏ ÌëúÏ†ï Îì± Ïπ≠Ï∞¨)
*   **üëé Í∞úÏÑ†Ìï† Ï†ê:**
    *   (ÏùåÏÑ±/ÏòÅÏÉÅ Î∂ÑÏÑù Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú ÎßêÌïòÍ∏∞ ÏäµÍ¥Ä, ÏãúÏÑ†, ÏûêÏÑ∏ Îì±Ïóê ÎåÄÌïú Ï°∞Ïñ∏)

---

## **Ï¥ùÏ†ê Î∞è Ï†úÏïà**
*   **Ï¥ùÏ†ê:** [ÏÑ∏ Ìï≠Î™©Ïùò ÌèâÍ∑† Ï†êÏàòÎ•º ÏÜåÏàòÏ†ê Ï≤´Ïß∏ ÏûêÎ¶¨ÍπåÏßÄ Í≥ÑÏÇ∞ÌïòÏó¨ ÌëúÏãú] / 5.0
*   **ÎßàÏßÄÎßâ Ï°∞Ïñ∏:**
    > ÏßÄÏõêÏûêÍ∞Ä Îã§Ïùå Î©¥Ï†ëÏóêÏÑú ÏµúÍ≥†Ïùò ÏÑ±Í≥ºÎ•º ÎÇº Ïàò ÏûàÎèÑÎ°ù, Í∞ÄÏû• Ï§ëÏöîÌïú ÌïµÏã¨ Ï°∞Ïñ∏ Ìïú Í∞ÄÏßÄÎ•º Í≤©Î†§Ïùò Î©îÏãúÏßÄÏôÄ Ìï®Íªò Ï†ÑÎã¨Ìï¥ Ï£ºÏÑ∏Ïöî.
"""

    headers = {
        "x-api-key": api_key,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
    }

    payload = {
        "model": claude_model,
        "max_tokens": 4096,
        "messages": [{"role": "user", "content": prompt}]
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=payload,
                timeout=180.0
            )
            response.raise_for_status()
            
            response_data = response.json()
            feedback_text = response_data['content'][0]['text']

        analysis_create = AnalysisCreate(
            interview_id=interview_id, 
            feedback_text=feedback_text,
            speech_rate=avg_speech_rate,
            silence_ratio=avg_silence_ratio,
            gaze_stability=gaze_stability,
            expression_stability=expression_stability,
            posture_stability=posture_stability
        )
        new_analysis = crud.analysis.create_analysis(db=db, obj_in=analysis_create)
        return new_analysis

    except httpx.HTTPStatusError as e:
        error_message = f"Claude API request failed with status {e.response.status_code} and response: {e.response.text}"
        print(error_message)
        raise HTTPException(status_code=500, detail=error_message)
    except Exception as e:
        error_message = f"An unexpected error occurred: {e}"
        print(error_message)
        raise HTTPException(status_code=500, detail=error_message)


@router.websocket("/ws/{interview_id}")
async def websocket_interview(
    websocket: WebSocket,
    interview_id: int,
    token: str,
):
    await websocket.accept()
    db: Session = SessionLocal()
    try:
        try:
            user = deps.get_user_from_token(db=db, token=token)
        except HTTPException as e:
            await websocket.send_json({"type": "error", "message": f"Authentication failed: {e.detail}"})
            await websocket.close(code=1008)
            return

        interview = crud.interview.get_interview(db, interview_id=interview_id)
        if not interview or interview.user_id != user.user_id:
            await websocket.send_json({"type": "error", "message": "Interview not found or access denied."})
            await websocket.close(code=1008)
            return

        questions = crud.interview.get_questions_by_interview(db, interview_id=interview_id)
        if not questions:
            await websocket.send_json({"type": "error", "message": "Interview questions not found."})
            await websocket.close(code=1008)
            return

        await websocket.send_json({"type": "system", "message": f"Interview session started. {len(questions)} questions will be asked.", "status": "connected"})
        
        for index, question in enumerate(questions):
            await websocket.send_json({"type": "question", "text": question.question_text, "question_number": index + 1, "total_questions": len(questions)})
            
            try:
                tts_model_name = os.getenv("TTS_MODEL_NAME", "gemini-2.5-flash-tts")
                tts_voice_name = os.getenv("TTS_VOICE_NAME", "ko-KR-Neural2-C")
                
                tts_client = tts.TextToSpeechClient()
                synthesis_input = tts.SynthesisInput(text=question.question_text)
                voice = tts.VoiceSelectionParams(
                    language_code="ko-KR",
                    name=tts_voice_name,
                    model_name=tts_model_name
                )
                audio_config = tts.AudioConfig(audio_encoding=tts.AudioEncoding.MP3)
                response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)
                await websocket.send_bytes(response.audio_content)
            except Exception as tts_error:
                print(f"TTS Error: {tts_error}")
                await websocket.send_json({"type": "error", "message": "Could not generate audio for the question."})

            print("Waiting to receive audio data as base64 text...")
            base64_audio_data = await websocket.receive_text()
            print("Base64 text received. Decoding...")
            audio_bytes = base64.b64decode(base64_audio_data)
            print(f"Decoded {len(audio_bytes)} bytes. Proceeding to transcription.")

            audio_dir = "audio_files"
            os.makedirs(audio_dir, exist_ok=True)
            
            audio_filename = f"{uuid.uuid4()}.wav"
            audio_path = os.path.join(audio_dir, audio_filename)

            try:
                if 'whisper_model' not in globals():
                    globals()['whisper_model'] = whisper.load_model("small")
                
                with open(audio_path, "wb") as f:
                    f.write(audio_bytes)
                
                result = globals()['whisper_model'].transcribe(audio_path, language="ko")
                print(f"Whisper transcription result: {result}")
                answer_text = result.get("text", "")
            except Exception as e:
                print(f"Error during transcription: {e}")
                answer_text = ""
            
            answer_create = AnswerCreate(
                question_id=question.question_id, 
                answer_text=answer_text,
                audio_path=audio_path
            )
            crud.interview.create_answer(db=db, obj_in=answer_create)
            
            await websocket.send_json({"type": "system", "message": f"Answer for question {index + 1} received.", "status": "processing"})

        await websocket.send_json({"type": "system", "message": "Interview finished. Thank you.", "status": "finished"})

    except WebSocketDisconnect:
        print(f"Client for interview {interview_id} disconnected.")
    except Exception as e:
        await websocket.send_json({"type": "error", "message": str(e)})
    finally:
        db.close()
        await websocket.close()


@router.post("/{interview_id}/video-analysis", status_code=200)
def handle_video_analysis(
    interview_id: int,
    request_data: VideoAnalysisRequest,
    db: Session = Depends(deps.get_db),
    current_user: models.User = Depends(deps.get_current_user),
):
    """
    Receive video landmark data, analyze it, and save the results to the
    video_analysis table.
    """
    interview = crud.interview.get_interview(db, interview_id=interview_id)
    if not interview or interview.user_id != current_user.user_id:
        raise HTTPException(status_code=404, detail="Interview not found or access denied")

    landmark_data = request_data.landmarks
    video_metrics = analyze_video_landmarks(landmark_data)

    # Check if video analysis for this interview already exists
    existing_video_analysis = crud.video_analysis.get_by_interview_id(db, interview_id=interview_id)
    if existing_video_analysis:
        # Optionally, you could update it, but for now, we'll just return a message.
        return {"message": "Video analysis data for this interview already exists."}

    video_analysis_create = VideoAnalysisCreate(
        interview_id=interview_id,
        **video_metrics
    )
    crud.video_analysis.create(db=db, obj_in=video_analysis_create)

    return {"message": "Video analysis data saved successfully."}
