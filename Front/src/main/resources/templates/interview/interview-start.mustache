{{>layout/header}}
<!-- MediaPipe CDN -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js" crossorigin="anonymous"></script>

<div class="h-20 md:h-24"></div>

<main class="container mx-auto px-6 py-12">
    <!-- 면접 준비 단계 -->
    <div id="setup-step">
        <div class="text-center mb-12 fade-in">
            <div class="w-20 h-20 bg-gradient-to-br from-blue-400 to-purple-400 rounded-3xl flex items-center justify-center mx-auto mb-6">
                <svg class="w-10 h-10 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                          d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z"></path>
                </svg>
            </div>
            <h1 class="text-4xl md:text-5xl font-bold text-gray-800 mb-6">AI 모의 면접</h1>
            <p class="text-xl text-gray-600 max-w-3xl mx-auto">실제 면접처럼 AI와 대화하며 면접을 연습하세요.</p>
        </div>

        <div class="max-w-4xl mx-auto bg-white rounded-3xl p-8 shadow-lg fade-in-delay">
            <h2 class="text-2xl font-bold text-gray-800 mb-6">면접 환경 설정</h2>
            <div id="permissions-alert"
                 class="hidden bg-yellow-50 border-l-4 border-yellow-400 text-yellow-700 p-4 mb-6 rounded-lg"
                 role="alert">
                <p class="font-bold flex items-center">
                    <svg class="w-5 h-5 mr-2" fill="currentColor" viewBox="0 0 20 20">
                        <path fill-rule="evenodd"
                              d="M8.257 3.099c.765-1.36 2.722-1.36 3.486 0l5.58 9.92c.75 1.334-.213 2.98-1.742 2.98H4.42c-1.53 0-2.493-1.646-1.743-2.98l5.58-9.92zM11 13a1 1 0 11-2 0 1 1 0 012 0zm-1-8a1 1 0 00-1 1v3a1 1 0 002 0V6a1 1 0 00-1-1z"
                              clip-rule="evenodd"></path>
                    </svg>
                    권한 필요
                </p>
                <p>모의 면접을 진행하려면 마이크와 카메라 접근 권한이 필요합니다. 브라우저의 권한 요청을 허용해주세요.</p>
            </div>

            <!-- 기기 설정 -->
            <div class="space-y-6">
                <div>
                    <label for="video-source" class="block text-sm font-semibold text-gray-700 mb-2 flex items-center">
                        <svg class="w-5 h-5 mr-2 text-blue-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                                  d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z"></path>
                        </svg>
                        카메라 선택
                    </label>
                    <select id="video-source"
                            class="w-full p-3 border-2 border-gray-200 rounded-xl focus:border-blue-400 focus:outline-none transition-colors"></select>
                    <p id="no-webcam-alert" class="hidden text-red-500 text-sm mt-2 flex items-center">
                        <svg class="w-4 h-4 mr-1" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd"
                                  d="M10 18a8 8 0 100-16 8 8 0 000 16zM8.707 7.293a1 1 0 00-1.414 1.414L8.586 10l-1.293 1.293a1 1 0 101.414 1.414L10 11.414l1.293 1.293a1 1 0 001.414-1.414L11.414 10l1.293-1.293a1 1 0 00-1.414-1.414L10 8.586 8.707 7.293z"
                                  clip-rule="evenodd"></path>
                        </svg>
                        웹캠을 찾을 수 없습니다. 음성으로만 면접이 진행됩니다.
                    </p>

                    <!-- IP 웹캠 설정 영역 (기본 숨김) -->
                    <div id="ip-webcam-config" class="mt-3 hidden">
                        <label for="ip-webcam-url" class="block text-sm font-semibold text-gray-700 mb-1">
                            스마트폰 IP 웹캠 주소
                        </label>
                        <input
                                id="ip-webcam-url"
                                type="text"
                                class="w-full p-2.5 border-2 border-gray-200 rounded-xl focus:border-blue-400 focus:outline-none text-sm"
                                placeholder="예: http://192.168.0.10:8080/video"
                        />
                        <p class="text-xs text-gray-500 mt-1">
                            스마트폰 IP 웹캠 앱에서 표시되는 스트림 주소를 입력하세요.
                        </p>
                    </div>
                </div>

                <div>
                    <label for="audio-source" class="block text-sm font-semibold text-gray-700 mb-2 flex items-center">
                        <svg class="w-5 h-5 mr-2 text-blue-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                                  d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"></path>
                        </svg>
                        마이크 선택
                    </label>
                    <select id="audio-source"
                            class="w-full p-3 border-2 border-gray-200 rounded-xl focus:border-blue-400 focus:outline-none transition-colors"></select>
                </div>
            </div>

            <!-- 면접 시작 버튼 -->
            <div class="text-center mt-10">
                <button id="start-interview-btn"
                        class="bg-gradient-to-r from-blue-400 to-purple-400 text-white px-12 py-4 rounded-2xl text-lg font-semibold hover:from-blue-500 hover:to-purple-500 transition-all transform hover:scale-105 shadow-lg flex items-center mx-auto space-x-2">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                              d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z"></path>
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                              d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
                    </svg>
                    <span>면접 시작하기</span>
                </button>
            </div>
        </div>
    </div>

    <!-- 면접 진행 단계 (초기에는 숨김) -->
    <div id="interview-step" class="hidden">
        <div class="grid lg:grid-cols-3 gap-8">
            <!-- 왼쪽: 질문 및 상태 -->
            <div class="lg:col-span-1 bg-white rounded-3xl p-8 shadow-lg h-fit">
                <h2 class="text-2xl font-bold text-gray-800 mb-4 flex items-center">
                    <div class="w-10 h-10 bg-gradient-to-br from-blue-400 to-purple-400 rounded-xl flex items-center justify-center mr-3">
                        <svg class="w-5 h-5 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                                  d="M8.228 9c.549-1.165 2.03-2 3.772-2 2.21 0 4 1.343 4 3 0 1.4-1.278 2.575-3.006 2.907-.542.104-.994.54-.994 1.093m0 3h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
                        </svg>
                    </div>
                    면접 질문
                </h2>
                <div id="question-display"
                     class="p-6 bg-gradient-to-br from-blue-50 to-purple-50 rounded-2xl min-h-[120px] text-lg text-gray-800 border-2 border-blue-200">
                    면접이 시작되면 여기에 질문이 표시됩니다.
                </div>

                <!-- 진행률 -->
                <div class="mt-8">
                    <div class="flex justify-between items-center mb-2">
                        <p class="text-sm font-semibold text-gray-700">진행 상황</p>
                        <p class="text-sm text-gray-600">질문 <span id="current-question-num"
                                                                  class="font-bold text-blue-500">0</span> / <span
                                id="total-question-num" class="font-bold text-blue-500">0</span></p>
                    </div>
                    <div class="w-full bg-gray-200 rounded-full h-3">
                        <div id="progress-bar"
                             class="bg-gradient-to-r from-blue-400 to-purple-400 h-3 rounded-full transition-all duration-500"
                             style="width: 0%"></div>
                    </div>
                </div>

                <!-- 녹화 인디케이터 -->
                <div id="recording-indicator" class="hidden mt-6 p-4 bg-red-50 rounded-2xl border-2 border-red-200">
                    <div class="flex items-center">
                        <span class="relative flex h-4 w-4 mr-3">
                            <span class="animate-ping absolute inline-flex h-full w-full rounded-full bg-red-400 opacity-75"></span>
                            <span class="relative inline-flex rounded-full h-4 w-4 bg-red-500"></span>
                        </span>
                        <span class="text-red-600 font-semibold">답변 녹화 중...</span>
                    </div>
                </div>
            </div>

            <!-- 오른쪽: 웹캠 및 컨트롤 버튼 -->
            <div class="lg:col-span-2">
                <div class="bg-gradient-to-br from-gray-900 to-gray-800 rounded-3xl p-4 shadow-2xl relative overflow-hidden">
                    <div class="relative w-full h-full">
                        <video id="user-video" class="w-full h-full rounded-2xl" autoplay muted playsinline></video>
                        <canvas id="debug-canvas" class="absolute top-0 left-0 w-full h-full rounded-2xl"></canvas>

                        <!-- Debug Info Overlay -->
                        <div id="debug-info" class="absolute top-4 left-4 bg-black bg-opacity-70 text-white px-4 py-3 rounded-lg text-sm font-mono">
                            <div>Frames: <span id="frame-count">0</span></div>
                            <div>Face: <span id="face-status" class="text-gray-400">대기중</span></div>
                            <div>Pose: <span id="pose-status" class="text-gray-400">대기중</span></div>
                        </div>
                    </div>

                    <div class="absolute bottom-8 left-1/2 -translate-x-1/2 flex gap-4">
                        <button id="next-question-btn"
                                class="bg-gradient-to-r from-blue-400 to-purple-400 text-white px-10 py-4 rounded-full text-lg font-semibold shadow-2xl hover:from-blue-500 hover:to-purple-500 transition-all transform hover:scale-105 flex items-center space-x-2">
                            <span>다음 질문</span>
                            <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                                      d="M13 7l5 5m0 0l-5 5m5-5H6"></path>
                            </svg>
                        </button>
                        <button id="toggle-debug-btn"
                                class="bg-gray-700 text-white px-6 py-4 rounded-full text-sm font-semibold shadow-lg hover:bg-gray-600 transition-colors">
                            디버그 ON
                        </button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- 질문 목록 (JavaScript에서 사용하기 위해 숨겨둠) -->
    <div id="questions-data" class="hidden">
        {{#questions}}
            <div class="question">{{.}}</div>
        {{/questions}}
    </div>
</main>

<style>
    .fade-in {
        animation: fadeIn 0.8s ease-out;
    }
    .fade-in-delay {
        animation: fadeIn 0.8s ease-out 0.2s both;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
</style>

<script>
    document.addEventListener('DOMContentLoaded', async () => {
        // UI Elements
        const setupStep = document.getElementById('setup-step');
        const interviewStep = document.getElementById('interview-step');
        const videoSelect = document.getElementById('video-source');
        const audioSelect = document.getElementById('audio-source');
        const ipWebcamConfig = document.getElementById('ip-webcam-config');
        const ipWebcamInput = document.getElementById('ip-webcam-url');
        const startBtn = document.getElementById('start-interview-btn');
        const userVideo = document.getElementById('user-video');
        const questionDisplay = document.getElementById('question-display');
        const recordingIndicator = document.getElementById('recording-indicator');
        const nextQuestionBtn = document.getElementById('next-question-btn');
        const permissionsAlert = document.getElementById('permissions-alert');
        const noWebcamAlert = document.getElementById('no-webcam-alert');
        const progressBar = document.getElementById('progress-bar');
        const currentQuestionNumSpan = document.getElementById('current-question-num');
        const totalQuestionNumSpan = document.getElementById('total-question-num');
        const debugCanvas = document.getElementById('debug-canvas');
        const debugCtx = debugCanvas.getContext('2d');
        const toggleDebugBtn = document.getElementById('toggle-debug-btn');

        // State
        let mediaRecorder;
        let recordedChunks = [];
        let localStream;
        let webSocket;
        let interviewId;
        let currentQuestionIndex = 0;

        // Video analysis state
        let landmarkData = [];  // Stores all landmark frames
        let faceMesh = null;
        let pose = null;
        let lastLandmarkTime = 0;
        const LANDMARK_SAMPLE_INTERVAL = 500;  // Capture landmarks every 500ms
        let debugMode = true;  // Debug visualization enabled by default

        // 1. 초기화: 장치 목록 가져오기 및 권한 요청
        async function init() {
            try {
                // 권한 요청
                localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                permissionsAlert.classList.add('hidden');
                userVideo.srcObject = localStream;

                // 장치 목록 가져오기
                const devices = await navigator.mediaDevices.enumerateDevices();
                const videoDevices = devices.filter(device => device.kind === 'videoinput');
                const audioDevices = devices.filter(device => device.kind === 'audioinput');

                if (videoDevices.length === 0) {
                    noWebcamAlert.classList.remove('hidden');
                }

                videoDevices.forEach(device => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    option.text = device.label || `Camera ${videoSelect.length + 1}`;
                    videoSelect.appendChild(option);
                });

                // 스마트폰 IP 웹캠 사용 옵션 추가
                const ipOption = document.createElement('option');
                ipOption.value = 'ip-webcam';
                ipOption.text = '스마트폰 IP 웹캠 사용';
                videoSelect.appendChild(ipOption);

                audioDevices.forEach(device => {
                    const option = document.createElement('option');
                    option.value = device.deviceId;
                    option.text = device.label || `Microphone ${audioSelect.length + 1}`;
                    audioSelect.appendChild(option);
                });

                // Initialize MediaPipe for video analysis
                initializeMediaPipe();

            } catch (err) {
                console.error("Error accessing media devices.", err);
                permissionsAlert.classList.remove('hidden');
                startBtn.disabled = true;
            }
        }

        // Initialize MediaPipe Face Mesh and Pose
        function initializeMediaPipe() {
            // Face Mesh
            faceMesh = new FaceMesh({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
                }
            });
            faceMesh.setOptions({
                maxNumFaces: 1,
                refineLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            faceMesh.onResults(onFaceMeshResults);

            // Pose
            pose = new Pose({
                locateFile: (file) => {
                    return `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`;
                }
            });
            pose.setOptions({
                modelComplexity: 1,
                smoothLandmarks: true,
                minDetectionConfidence: 0.5,
                minTrackingConfidence: 0.5
            });
            pose.onResults(onPoseResults);

            console.log("MediaPipe initialized");
        }

        let tempFaceLandmarks = null;
        let tempPoseLandmarks = null;

        function onFaceMeshResults(results) {
            if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
                tempFaceLandmarks = results.multiFaceLandmarks[0];
                updateDebugStatus('face', true);
                saveLandmarkFrame();

                // Draw debug visualization
                if (debugMode) {
                    drawFaceMesh(results);
                }
            } else {
                updateDebugStatus('face', false);
            }
        }

        function onPoseResults(results) {
            if (results.poseLandmarks) {
                tempPoseLandmarks = results.poseLandmarks;
                updateDebugStatus('pose', true);
                saveLandmarkFrame();

                // Draw debug visualization
                if (debugMode) {
                    drawPose(results);
                }
            } else {
                updateDebugStatus('pose', false);
            }
        }

        // Update debug info overlay
        function updateDebugStatus(type, detected) {
            const statusSpan = document.getElementById(`${type}-status`);
            if (statusSpan) {
                if (detected) {
                    statusSpan.textContent = '감지됨';
                    statusSpan.className = 'text-green-400';
                } else {
                    statusSpan.textContent = '미감지';
                    statusSpan.className = 'text-red-400';
                }
            }
        }

        // Set canvas size to match video
        function resizeCanvas() {
            debugCanvas.width = userVideo.videoWidth;
            debugCanvas.height = userVideo.videoHeight;
        }

        // Draw Face Mesh on canvas
        function drawFaceMesh(results) {
            if (!debugCanvas.width) resizeCanvas();

            debugCtx.save();
            debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);

            if (results.multiFaceLandmarks) {
                for (const landmarks of results.multiFaceLandmarks) {
                    // Draw face mesh connections
                    window.drawConnectors(debugCtx, landmarks, window.FACEMESH_TESSELATION,
                        {color: '#C0C0C070', lineWidth: 1});
                    window.drawConnectors(debugCtx, landmarks, window.FACEMESH_RIGHT_EYE,
                        {color: '#FF3030', lineWidth: 2});
                    window.drawConnectors(debugCtx, landmarks, window.FACEMESH_LEFT_EYE,
                        {color: '#30FF30', lineWidth: 2});
                    window.drawConnectors(debugCtx, landmarks, window.FACEMESH_LIPS,
                        {color: '#E0E0E0', lineWidth: 2});
                }
            }

            debugCtx.restore();
        }

        // Draw Pose on canvas
        function drawPose(results) {
            if (!debugCanvas.width) resizeCanvas();

            if (results.poseLandmarks) {
                // Draw pose connections
                window.drawConnectors(debugCtx, results.poseLandmarks, window.POSE_CONNECTIONS,
                    {color: '#00FF00', lineWidth: 4});
                window.drawLandmarks(debugCtx, results.poseLandmarks,
                    {color: '#FF0000', lineWidth: 2, radius: 6});
            }
        }

        // Toggle debug mode
        toggleDebugBtn.addEventListener('click', () => {
            debugMode = !debugMode;
            toggleDebugBtn.textContent = debugMode ? '디버그 ON' : '디버그 OFF';
            toggleDebugBtn.classList.toggle('bg-gray-700', debugMode);
            toggleDebugBtn.classList.toggle('bg-green-600', !debugMode);

            if (!debugMode) {
                // Clear canvas when debug mode is off
                debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
            }
        });

        function saveLandmarkFrame() {
            const now = Date.now();
            if (now - lastLandmarkTime < LANDMARK_SAMPLE_INTERVAL) {
                return;  // Skip this frame (sampling)
            }

            if (tempFaceLandmarks && tempPoseLandmarks) {
                landmarkData.push({
                    face: tempFaceLandmarks,
                    pose: tempPoseLandmarks
                });
                lastLandmarkTime = now;

                // Update frame count display
                const frameCountSpan = document.getElementById('frame-count');
                if (frameCountSpan) {
                    frameCountSpan.textContent = landmarkData.length;
                }

                console.log(`Captured landmark frame ${landmarkData.length}`);
            }
        }

        async function processVideoFrame() {
            if (userVideo.readyState === userVideo.HAVE_ENOUGH_DATA && faceMesh && pose) {
                await faceMesh.send({image: userVideo});
                await pose.send({image: userVideo});
            }
            requestAnimationFrame(processVideoFrame);
        }

        // 2. 면접 시작 처리
        startBtn.addEventListener('click', async () => {
            try {
                const resumeId = "{{resumeId}}";
                const token = "{{token}}";

                const response = await fetch(`/api/interviews?resume_id=${resumeId}`, {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${token}`
                    }
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.detail || 'Failed to create interview session.');
                }

                const sessionData = await response.json();
                interviewId = sessionData.interview_id;

                // UI 전환
                setupStep.classList.add('hidden');
                interviewStep.classList.remove('hidden');

                // Start video frame processing for landmark extraction
                processVideoFrame();

                // 웹소켓 연결
                const wsUrl = `ws://127.0.0.1:8000/api/v1/interviews/ws/${interviewId}?token=${token}`;
                webSocket = new WebSocket(wsUrl);
                setupWebSocketHandlers();

            } catch (error) {
                console.error("Failed to start interview:", error);
                alert("면접 세션을 시작하는 데 실패했습니다: " + error.message);
            }
        });

        // 3. 웹소켓 핸들러 설정
        function setupWebSocketHandlers() {
            webSocket.onopen = () => console.log("WebSocket connection established.");
            webSocket.onclose = () => console.log("WebSocket connection closed.");
            webSocket.onerror = (err) => console.error("WebSocket error:", err);

            webSocket.onmessage = (event) => {
                if (event.data instanceof Blob) {
                    // 질문 오디오 재생
                    const audioUrl = URL.createObjectURL(event.data);
                    const audio = new Audio(audioUrl);
                    audio.play();
                    audio.onended = startRecording; // 오디오 재생 끝나면 녹화 시작
                } else {
                    const message = JSON.parse(event.data);
                    handleWebSocketMessage(message);
                }
            };
        }

        // 4. 웹소켓 메시지 처리
        async function handleWebSocketMessage(message) {
            console.log("Received message:", message);
            if (message.type === 'question') {
                questionDisplay.textContent = message.text;
                currentQuestionIndex = message.question_number;
                if (message.total_questions) {
                    totalQuestionNumSpan.textContent = message.total_questions;
                }
                updateProgress();
            } else if (message.type === 'system' && message.status === 'finished') {
                console.log('Interview finished. Sending video analysis data...');

                // Send landmark data to backend
                await sendVideoAnalysisData();

                alert('면접이 종료되었습니다. 분석 결과 페이지로 이동합니다.');
                window.location.href = `/interview/${interviewId}/results`;
            }
        }

        // Send video analysis data to backend
        async function sendVideoAnalysisData() {
            if (landmarkData.length === 0) {
                console.log('No landmark data collected. Skipping video analysis.');
                return;
            }

            try {
                const token = "{{token}}";
                const payload = { landmarks: landmarkData };  // Wrap in object with 'landmarks' key

                const response = await fetch(`/api/interviews/${interviewId}/video-analysis`, {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${token}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    console.error('Failed to send video analysis data:', await response.text());
                } else {
                    console.log(`Successfully sent ${landmarkData.length} landmark frames for analysis.`);
                }
            } catch (error) {
                console.error('Error sending video analysis data:', error);
            }
        }

        // 5. 녹화 시작
        function startRecording() {
            console.log("Starting recording...");
            recordedChunks = [];
            const options = { mimeType: 'audio/webm;codecs=opus' }; // 오디오만 녹음

            // 선택된 장치로 스트림 다시 설정
            const audioSource = audioSelect.value;
            const constraints = { audio: { deviceId: audioSource ? { exact: audioSource } : undefined } };

            navigator.mediaDevices.getUserMedia(constraints).then(stream => {
                mediaRecorder = new MediaRecorder(stream, options);
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                mediaRecorder.onstart = () => recordingIndicator.classList.remove('hidden');
                mediaRecorder.onstop = () => recordingIndicator.classList.add('hidden');
                mediaRecorder.start();
            });
        }

        // 6. 다음 질문 버튼 클릭 처리
        nextQuestionBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                mediaRecorder.onstop = () => {
                    const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                    sendData(blob);
                    recordingIndicator.classList.add('hidden');
                };
            }
        });

        // 7. 녹화된 데이터 서버로 전송
        function sendData(blob) {
            const reader = new FileReader();
            reader.onloadend = () => {
                // "data:audio/webm;base64," 부분을 제거하고 순수 Base64 데이터만 전송
                const base64String = reader.result.split(',')[1];
                if (webSocket && webSocket.readyState === WebSocket.OPEN) {
                    webSocket.send(base64String);
                    console.log("Sent audio data as Base64.");
                }
            };
            reader.readAsDataURL(blob);
        }

        // 8. 진행률 업데이트
        function updateProgress() {
            const totalQuestions = parseInt(totalQuestionNumSpan.textContent, 10);
            const progress = (currentQuestionIndex / totalQuestions) * 100;
            progressBar.style.width = `${progress}%`;
            currentQuestionNumSpan.textContent = currentQuestionIndex;
        }

        // 페이지 로드 시 초기화 함수 실행
        init();
    });
</script>

{{>layout/footer}}